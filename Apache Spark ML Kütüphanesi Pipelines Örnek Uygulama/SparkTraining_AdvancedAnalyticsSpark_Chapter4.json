{"paragraphs":[{"user":"admin","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514139994002_851669135","id":"20171224-202634_472315100","dateCreated":"2017-12-24T20:26:34+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18469","text":"%md\n\nİngiliz bilimci Sir Francis Galton yaptığı ölçümlerde ortalamanın çok üzerinde iri, uzun veya kısa, küçük ailelerin çocuklarının da uzun veya kısa olduğunu ancak genel ortalama ile aile arasında kaldığını ölçtü. Yani upuzun bir basketbolcunun oğlu da ortalamadan daha uzun oluyordu ancak kendisindan daha uzun değil. Böylelikle insanların fiziksel özellikleri insanlık ortalamasına doğru itiliyordu. Bunu grafiğe döktüğünde ortaya çıkan çizginin doğrusal olduğunu farketti. Eğim pozitif ve birden azıcık küçüktü. Galton bu olayı ortalamaya doğru regresyon diye ifade etti.","dateUpdated":"2017-12-24T21:06:29+0200","dateFinished":"2017-12-24T21:06:05+0200","dateStarted":"2017-12-24T21:06:04+0200","title":"Giriş","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>İngiliz bilimci Sir Francis Galton yaptığı ölçümlerde ortalamanın çok üzerinde iri, uzun veya kısa, küçük ailelerin çocuklarının da uzun veya kısa olduğunu ancak genel ortalama ile aile arasında kaldığını ölçtü. Yani upuzun bir basketbolcunun oğlu da ortalamadan daha uzun oluyordu ancak kendisindan daha uzun değil. Böylelikle insanların fiziksel özellikleri insanlık ortalamasına doğru itiliyordu. Bunu grafiğe döktüğünde ortaya çıkan çizginin doğrusal olduğunu farketti. Eğim pozitif ve birden azıcık küçüktü. Galton bu olayı ortalamaya doğru regresyon diye ifade etti.</p>\n</div>"}]}},{"text":"%md\nRegression genel olarak büyüklük, gelir veya sıcaklık gibi nümerik değeri tahmin etmektle ilgilidir. Kategorik bir değeri tahmin etmekle ilgilidir, Resimdeki kedidir veya değildir. Hem regresyon hem de sınıflandırma güdümlü (supervised) yöntemler altındadır.","user":"admin","dateUpdated":"2017-12-24T21:06:09+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514140403631_-1036327655","id":"20171224-203323_1771828614","dateCreated":"2017-12-24T20:33:23+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18539","dateFinished":"2017-12-24T21:06:09+0200","dateStarted":"2017-12-24T21:06:09+0200","title":"Fast Forward to Regression","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Regression genel olarak büyüklük, gelir veya sıcaklık gibi nümerik değeri tahmin etmektle ilgilidir. Kategorik bir değeri tahmin etmekle ilgilidir, Resimdeki kedidir veya değildir. Hem regresyon hem de sınıflandırma güdümlü (supervised) yöntemler altındadır.</p>\n</div>"}]}},{"text":"%md\nBugünün havasıyla yarınınkini tahmin etmek. Bunun için nitelikler lazım. Özellik, nitelik, boyut, prediktör, ya da değişken. Bugünle ilgili elimizde şu bilgiler olsun: high temperature 13.1, low temperature 19.0, average humidity 0.73, have genel durumu bulutlu, prediktör 1. Bu beş niteliği yanyana yazdığımızda 13.1, 19.0, 0.73, bulutlu, 1 feature vector olur ve bu bilgi ile herhangi bir güne ait havayı tanımlayabiliriz. Buradaki özelliklerin hepsi aynı türden değil. İlk ikisi derece, üçüncüsünde birim yok, dördüncü rakam bile değil, beşinci ise her zaman pozitif tam sayı.\n\nNitelikler kabaca ikiye ayrılır kategorik ve nümerik. ","user":"admin","dateUpdated":"2017-12-24T21:07:10+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514141275570_-31694082","id":"20171224-204755_1070736044","dateCreated":"2017-12-24T20:47:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18604","dateFinished":"2017-12-24T21:07:10+0200","dateStarted":"2017-12-24T21:07:10+0200","title":"Vectors and Features","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Bugünün havasıyla yarınınkini tahmin etmek. Bunun için nitelikler lazım. Özellik, nitelik, boyut, prediktör, ya da değişken. Bugünle ilgili elimizde şu bilgiler olsun: high temperature 13.1, low temperature 19.0, average humidity 0.73, have genel durumu bulutlu, prediktör 1. Bu beş niteliği yanyana yazdığımızda 13.1, 19.0, 0.73, bulutlu, 1 feature vector olur ve bu bilgi ile herhangi bir güne ait havayı tanımlayabiliriz. Buradaki özelliklerin hepsi aynı türden değil. İlk ikisi derece, üçüncüsünde birim yok, dördüncü rakam bile değil, beşinci ise her zaman pozitif tam sayı.</p>\n<p>Nitelikler kabaca ikiye ayrılır kategorik ve nümerik.</p>\n</div>"}]}},{"text":"%md\nHava durumuna ait nitelikler ile bir sonraki günün hava sıcaklığı tahmin edilecekse regresyon, hava durumu tahmin edilecekse sınıflandırma kullanılır. ","user":"admin","dateUpdated":"2017-12-24T21:54:44+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514142447405_-1529680846","id":"20171224-210727_1293961026","dateCreated":"2017-12-24T21:07:27+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18734","dateFinished":"2017-12-24T21:54:45+0200","dateStarted":"2017-12-24T21:54:44+0200","title":"Training Examples","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Hava durumuna ait nitelikler ile bir sonraki günün hava sıcaklığı tahmin edilecekse regresyon, hava durumu tahmin edilecekse sınıflandırma kullanılır.</p>\n</div>"}]}},{"text":"%md\nKarar ağaçları hem kategorik hem nümerik özelliklerle çalışabilir. Sıra dışı değerlerden çok fazla etkilenmezler. Değişik tür ve ölçekte niteliklerle çalışırlar, normalizasyon gerektirmezler. Bu ünitede veri setine DecisionTree ve RandomForest modelleri uygulanacaktır. Aslında insanlar olarak bizler de karar ağaçlarında izlenen mantığı günlük hayatımızda farkında olmadan kullanırız. Sütün  bozulup bozulmadığının kontrolü mesela; önce tarihe bak, tarih yeni geçmişse kokla, bişey anlamadıysan birazcık tat. Her bir aşama da cevabın evet veya hayır olacak ve ona göre farklı davranacaksın.  \n\nEvcil hayvan dükkanına alınan robot. Robot, dükkan açılmadan hangi hayvanın çocuk için iyi bir hayvan olacağını tahmin etmeye çalışıyor. Dükkan sahibi hayvanon adı, ağırlığı, kaç ayaklı olduğu, rengi ve iyi bir hayvan oluğ olmadığına dair bir liste hazırlıyor. Bu özelliklerden ismin sonucu tahmin etmede hiçbir etkisi olmadığı açık. Çünkü isim herhangi bir hayvana ait olabilir. Öyleyse geriye üç özellik kalıyor (ağırlık ve ayak sayısı, nümerik) renk ise kategorik. ","user":"admin","dateUpdated":"2017-12-24T22:00:54+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514142992273_-37430854","id":"20171224-211632_1229798476","dateCreated":"2017-12-24T21:16:32+0200","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18796","title":"Decision Trees and Forests"},{"title":"Veriyi yükle (Covtype DataSet)","text":"// Veri ABD Colorado Eyaleti arsa/parsel bilgilerini içeriyor\n// Her bir parsel için şu özellikler mevcut: rakım(metre), eğim(derece), gölge durumu, toprak türü (aynı zamanda bilinen orman örtüsünden hangisi ile kaplı olduğu) Bu veri setinde parselin özelliklerinden hangi tür ormanla kaplı olduğu tahmin edilecek. Bunun için 54 özellik var. Wilderness_Area'da dört farlı, Soil_Type'da 40 farklı değer var bunlar 1-of-n veya one-hot encodinlik değerler. \n// 581.012 örnek var. Gerçek değerler. Büyük veri sayılmasa da büyük veri ve ölçeklenebilirliğe örnek için yeterli.  Veri basit csv formatında. Veride header yok. Bu sebeple  option(\"header\",\"true\") kullanmıyoruz. Nitelikler, _c0, _c1, _c2.... şeklinde isimlendirilecek.\n\n\nval dataWithoutHeader = spark.read.option(\"inferSchema\",\"true\").option(\"header\",\"false\").csv(\"/user/erkan/veri_setlerim/covtype.data\")","user":"admin","dateUpdated":"2017-12-24T22:22:57+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndataWithoutHeader: org.apache.spark.sql.DataFrame = [_c0: int, _c1: int ... 53 more fields]\n"}]},"apps":[],"jobName":"paragraph_1513885868014_-541744606","id":"20171221-215108_2061658470","dateCreated":"2017-12-21T21:51:08+0200","dateStarted":"2017-12-21T21:52:56+0200","dateFinished":"2017-12-21T21:54:27+0200","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:17163"},{"title":"Sütun isimleri","text":"val colNames = Seq(\n\"Elevation\",\"Aspect\",\"Slope\",\n\"Horizontal_Distance_To_Hyrology\",\"Vertical_Distance_To_Hyrology\",\n\"Horizontal_Distance_To_Roadways\",\n\"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\",\n\"Horizontal_Distance_To_Fire_Points\"\n)++(\n(0 until 4).map(i => s\"Wilderness_Area_$i\")\n)++(\n(0 until 40).map(i => s\"Soil_Type_$i\")\n)++Seq(\"Cover_Type\")","user":"admin","dateUpdated":"2017-12-24T22:24:38+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"title":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"colNames: Seq[String] = List(Elevation, Aspect, Slope, Horizontal_Distance_To_Hyrology, Vertical_Distance_To_Hyrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, Horizontal_Distance_To_Fire_Points, Wilderness_Area_0, Wilderness_Area_1, Wilderness_Area_2, Wilderness_Area_3, Soil_Type_0, Soil_Type_1, Soil_Type_2, Soil_Type_3, Soil_Type_4, Soil_Type_5, Soil_Type_6, Soil_Type_7, Soil_Type_8, Soil_Type_9, Soil_Type_10, Soil_Type_11, Soil_Type_12, Soil_Type_13, Soil_Type_14, Soil_Type_15, Soil_Type_16, Soil_Type_17, Soil_Type_18, Soil_Type_19, Soil_Type_20, Soil_Type_21, Soil_Type_22, Soil_Type_23, Soil_Type_24, Soil_Type_25, Soil_Type_26, Soil_Type_27, Soil_Type_28, Soil_Type_29, Soil_Type_30, Soil_Type_31, Soil_Type_32, Soil_Type_33, Soil_Type_34, Soil_Ty..."}]},"apps":[],"jobName":"paragraph_1513885976482_-867642248","id":"20171221-215256_2119860689","dateCreated":"2017-12-21T21:52:56+0200","dateStarted":"2017-12-22T05:48:59+0200","dateFinished":"2017-12-22T05:49:49+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17168"},{"text":"colNames.length","user":"admin","dateUpdated":"2017-12-22T05:49:57+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres3: Int = 55\n"}]},"apps":[],"jobName":"paragraph_1513914172011_258363199","id":"20171222-054252_459551420","dateCreated":"2017-12-22T05:42:52+0200","dateStarted":"2017-12-22T05:49:57+0200","dateFinished":"2017-12-22T05:50:00+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17169"},{"title":"Sütun isimleriyle veriyi birleştirelim","text":"val data = dataWithoutHeader.toDF(colNames:_*).withColumn(\"Cover_Type\", $\"Cover_Type\".cast(\"double\"))","user":"admin","dateUpdated":"2017-12-22T05:50:02+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\ndata: org.apache.spark.sql.DataFrame = [Elevation: int, Aspect: int ... 53 more fields]\n"}]},"apps":[],"jobName":"paragraph_1513913620870_-24067685","id":"20171222-053340_585720002","dateCreated":"2017-12-22T05:33:40+0200","dateStarted":"2017-12-22T05:50:02+0200","dateFinished":"2017-12-22T05:50:07+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17170"},{"text":"data.head","user":"admin","dateUpdated":"2017-12-22T05:50:12+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres4: org.apache.spark.sql.Row = [2596,51,3,258,0,510,221,232,148,6279,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,5.0]\n"}]},"apps":[],"jobName":"paragraph_1513913975936_-2047324233","id":"20171222-053935_41983674","dateCreated":"2017-12-22T05:39:35+0200","dateStarted":"2017-12-22T05:50:12+0200","dateFinished":"2017-12-22T05:50:22+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17171"},{"title":"Veriyi %90 Eğitim, %10 test olacak şekilde bölelim","text":"val Array(trainData, testData) = data.randomSplit(Array(0.9, 0.1))","user":"admin","dateUpdated":"2017-12-22T22:29:22+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n\ntrainData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Elevation: int, Aspect: int ... 53 more fields]\ntestData: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Elevation: int, Aspect: int ... 53 more fields]\n"}]},"apps":[],"jobName":"paragraph_1513914087921_1643541317","id":"20171222-054127_1714020632","dateCreated":"2017-12-22T05:41:27+0200","dateStarted":"2017-12-22T22:29:23+0200","dateFinished":"2017-12-22T22:29:41+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17172"},{"title":"Girdilerin hepsini bir sütunda vector olarak toplama","text":"// Spark MLlib tüm girdileri bir sütun altında türü vektör olarak toplamak istiyor. Bunun için kütüphanede VectorAssembler sınıfı var.\nimport org.apache.spark.ml.feature.VectorAssembler\nval inputCols = trainData.columns.filter(_!=\"Cover_Type\")\nval assembler = new VectorAssembler().setInputCols(inputCols).setOutputCol(\"featureVector\")","user":"admin","dateUpdated":"2017-12-23T05:28:43+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.feature.VectorAssembler\ninputCols: Array[String] = Array(Elevation, Aspect, Slope, Horizontal_Distance_To_Hyrology, Vertical_Distance_To_Hyrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, Horizontal_Distance_To_Fire_Points, Wilderness_Area_0, Wilderness_Area_1, Wilderness_Area_2, Wilderness_Area_3, Soil_Type_0, Soil_Type_1, Soil_Type_2, Soil_Type_3, Soil_Type_4, Soil_Type_5, Soil_Type_6, Soil_Type_7, Soil_Type_8, Soil_Type_9, Soil_Type_10, Soil_Type_11, Soil_Type_12, Soil_Type_13, Soil_Type_14, Soil_Type_15, Soil_Type_16, Soil_Type_17, Soil_Type_18, Soil_Type_19, Soil_Type_20, Soil_Type_21, Soil_Type_22, Soil_Type_23, Soil_Type_24, Soil_Type_25, Soil_Type_26, Soil_Type_27, Soil_Type_28, Soil_Type_29, Soil_Type_30, Soil_Type_31, Soil_Type_32, Soil_Type_33, Soil_Type_34, Soi...\nassembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_acbe58fd18d3\n"}]},"apps":[],"jobName":"paragraph_1513973600445_2040276865","id":"20171222-221320_1582651952","dateCreated":"2017-12-22T22:13:20+0200","dateStarted":"2017-12-23T05:28:43+0200","dateFinished":"2017-12-23T05:29:27+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17173"},{"text":"val assembledTrainData = assembler.transform(trainData)\nassembledTrainData.select(\"featureVector\").show(truncate = false)","user":"admin","dateUpdated":"2017-12-23T05:40:16+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nassembledTrainData: org.apache.spark.sql.DataFrame = [Elevation: int, Aspect: int ... 54 more fields]\n+----------------------------------------------------------------------------------------------------+\n|featureVector                                                                                       |\n+----------------------------------------------------------------------------------------------------+\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1859.0,18.0,12.0,67.0,11.0,90.0,211.0,215.0,139.0,792.0,1.0,1.0])  |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1860.0,18.0,13.0,95.0,15.0,90.0,210.0,213.0,138.0,780.0,1.0,1.0])  |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1861.0,35.0,14.0,60.0,11.0,85.0,218.0,209.0,124.0,832.0,1.0,1.0])  |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1866.0,23.0,14.0,85.0,16.0,108.0,212.0,210.0,133.0,819.0,1.0,1.0]) |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1867.0,20.0,15.0,108.0,19.0,120.0,208.0,206.0,132.0,808.0,1.0,1.0])|\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1868.0,27.0,16.0,67.0,17.0,95.0,212.0,204.0,125.0,859.0,1.0,1.0])  |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1871.0,22.0,22.0,60.0,12.0,85.0,200.0,187.0,115.0,792.0,1.0,1.0])  |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1871.0,37.0,19.0,120.0,29.0,90.0,216.0,195.0,107.0,759.0,1.0,1.0]) |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1872.0,12.0,27.0,85.0,25.0,60.0,182.0,174.0,118.0,577.0,1.0,1.0])  |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1872.0,27.0,16.0,95.0,22.0,124.0,212.0,205.0,126.0,847.0,1.0,1.0]) |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1872.0,27.0,21.0,108.0,30.0,67.0,206.0,190.0,112.0,713.0,1.0,1.0]) |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1872.0,35.0,21.0,120.0,18.0,85.0,213.0,189.0,104.0,797.0,1.0,1.0]) |\n|(54,[0,1,2,5,6,7,8,9,13,18],[1874.0,18.0,14.0,90.0,208.0,209.0,135.0,793.0,1.0,1.0])                |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1876.0,25.0,17.0,124.0,26.0,150.0,209.0,200.0,123.0,836.0,1.0,1.0])|\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1876.0,29.0,19.0,124.0,34.0,90.0,210.0,195.0,115.0,750.0,1.0,1.0]) |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1877.0,19.0,18.0,85.0,25.0,108.0,204.0,199.0,127.0,886.0,1.0,1.0]) |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1877.0,27.0,24.0,90.0,18.0,95.0,201.0,179.0,104.0,780.0,1.0,1.0])  |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1877.0,28.0,22.0,127.0,35.0,85.0,205.0,185.0,107.0,706.0,1.0,1.0]) |\n|(54,[0,1,2,5,6,7,8,9,13,18],[1879.0,18.0,14.0,120.0,208.0,210.0,137.0,767.0,1.0,1.0])               |\n|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1879.0,23.0,18.0,108.0,28.0,134.0,207.0,200.0,124.0,875.0,1.0,1.0])|\n+----------------------------------------------------------------------------------------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1513973608865_-1014629402","id":"20171222-221328_1864590400","dateCreated":"2017-12-22T22:13:28+0200","dateStarted":"2017-12-23T05:40:16+0200","dateFinished":"2017-12-23T05:40:44+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17174"},{"text":"trainData.head","user":"admin","dateUpdated":"2017-12-23T05:48:15+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nres22: org.apache.spark.sql.Row = [1859,18,12,67,11,90,211,215,139,792,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.0]\n"}]},"apps":[],"jobName":"paragraph_1513975036360_-985383029","id":"20171222-223716_1722756529","dateCreated":"2017-12-22T22:37:16+0200","dateStarted":"2017-12-23T05:48:15+0200","dateFinished":"2017-12-23T05:48:24+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17175"},{"text":"// Şimdi karar ağacı modeli oluşturmak için hazırız\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\nimport scala.util.Random\n\nval classifier = new DecisionTreeClassifier().setSeed(Random.nextLong()).setLabelCol(\"Cover_Type\").setFeaturesCol(\"featureVector\").setPredictionCol(\"prediction\")","user":"admin","dateUpdated":"2017-12-23T09:57:36+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.classification.DecisionTreeClassifier\n\nimport scala.util.Random\n\nclassifier: org.apache.spark.ml.classification.DecisionTreeClassifier = dtc_b0ec97297c30\n"}]},"apps":[],"jobName":"paragraph_1513975038706_1790995683","id":"20171222-223718_1993136947","dateCreated":"2017-12-22T22:37:18+0200","dateStarted":"2017-12-23T09:57:36+0200","dateFinished":"2017-12-23T09:58:05+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17176"},{"text":"val model = classifier.fit(assembledTrainData)\nprintln(model.toDebugString)","user":"admin","dateUpdated":"2017-12-23T09:58:14+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nmodel: org.apache.spark.ml.classification.DecisionTreeClassificationModel = DecisionTreeClassificationModel (uid=dtc_b0ec97297c30) of depth 5 with 63 nodes\nDecisionTreeClassificationModel (uid=dtc_b0ec97297c30) of depth 5 with 63 nodes\n  If (feature 0 <= 3036.0)\n   If (feature 0 <= 2564.0)\n    If (feature 10 <= 0.0)\n     If (feature 0 <= 2464.0)\n      If (feature 3 <= 0.0)\n       Predict: 4.0\n      Else (feature 3 > 0.0)\n       Predict: 3.0\n     Else (feature 0 > 2464.0)\n      If (feature 17 <= 0.0)\n       Predict: 2.0\n      Else (feature 17 > 0.0)\n       Predict: 3.0\n    Else (feature 10 > 0.0)\n     If (feature 9 <= 5494.0)\n      If (feature 22 <= 0.0)\n       Predict: 2.0\n      Else (feature 22 > 0.0)\n       Predict: 2.0\n     Else (feature 9 > 5494.0)\n      If (feature 5 <= 552.0)\n       Predict: 2.0\n      Else (feature 5 > 552.0)\n       Predict: 5.0\n   Else (feature 0 > 2564.0)\n    If (feature 0 <= 2924.0)\n     If (feature 15 <= 0.0)\n      If (feature 17 <= 0.0)\n       Predict: 2.0\n      Else (feature 17 > 0.0)\n       Predict: 3.0\n     Else (feature 15 > 0.0)\n      If (feature 9 <= 1370.0)\n       Predict: 3.0\n      Else (feature 9 > 1370.0)\n       Predict: 3.0\n    Else (feature 0 > 2924.0)\n     If (feature 3 <= 120.0)\n      If (feature 35 <= 0.0)\n       Predict: 2.0\n      Else (feature 35 > 0.0)\n       Predict: 1.0\n     Else (feature 3 > 120.0)\n      If (feature 7 <= 216.0)\n       Predict: 2.0\n      Else (feature 7 > 216.0)\n       Predict: 2.0\n  Else (feature 0 > 3036.0)\n   If (feature 0 <= 3317.0)\n    If (feature 7 <= 239.0)\n     If (feature 0 <= 3125.0)\n      If (feature 3 <= 190.0)\n       Predict: 1.0\n      Else (feature 3 > 190.0)\n       Predict: 1.0\n     Else (feature 0 > 3125.0)\n      If (feature 5 <= 1006.0)\n       Predict: 1.0\n      Else (feature 5 > 1006.0)\n       Predict: 1.0\n    Else (feature 7 > 239.0)\n     If (feature 3 <= 331.0)\n      If (feature 0 <= 3187.0)\n       Predict: 1.0\n      Else (feature 0 > 3187.0)\n       Predict: 1.0\n     Else (feature 3 > 331.0)\n      If (feature 0 <= 3207.0)\n       Predict: 2.0\n      Else (feature 0 > 3207.0)\n       Predict: 1.0\n   Else (feature 0 > 3317.0)\n    If (feature 12 <= 0.0)\n     If (feature 3 <= 295.0)\n      If (feature 6 <= 206.0)\n       Predict: 1.0\n      Else (feature 6 > 206.0)\n       Predict: 7.0\n     Else (feature 3 > 295.0)\n      If (feature 10 <= 0.0)\n       Predict: 1.0\n      Else (feature 10 > 0.0)\n       Predict: 1.0\n    Else (feature 12 > 0.0)\n     If (feature 45 <= 0.0)\n      If (feature 0 <= 3373.0)\n       Predict: 7.0\n      Else (feature 0 > 3373.0)\n       Predict: 7.0\n     Else (feature 45 > 0.0)\n      If (feature 5 <= 1006.0)\n       Predict: 7.0\n      Else (feature 5 > 1006.0)\n       Predict: 1.0\n\n"}]},"apps":[],"jobName":"paragraph_1513975038099_2024538265","id":"20171222-223718_271475080","dateCreated":"2017-12-22T22:37:18+0200","dateStarted":"2017-12-23T09:58:14+0200","dateFinished":"2017-12-23T09:59:40+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17177"},{"text":"// Yukarıda oluşan DecisionTreeClassificationModel  bir dönüştürücü\n// Karar ağaçları girdi niteliklerin karara ne kadar etki ettiğini. Doğru bir tahmin için her bir niteliğin katkısı. \nmodel.featureImportances.toArray.zip(inputCols).sorted.reverse.foreach(println)","user":"admin","dateUpdated":"2017-12-23T16:02:45+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(0.7838572274501502,Elevation)\n(0.05021187952888828,Horizontal_Distance_To_Hyrology)\n(0.03449925431239023,Wilderness_Area_0)\n(0.03246357771284005,Hillshade_Noon)\n(0.028514485503743157,Soil_Type_3)\n(0.021904195361021832,Soil_Type_1)\n(0.01669356637779724,Soil_Type_31)\n(0.012433082761193747,Horizontal_Distance_To_Roadways)\n(0.011109868558297762,Wilderness_Area_2)\n(0.0037973890472850903,Soil_Type_21)\n(0.002605056975366612,Hillshade_9am)\n(0.0016127143643569508,Horizontal_Distance_To_Fire_Points)\n(2.9770204666889407E-4,Soil_Type_8)\n(0.0,Wilderness_Area_3)\n(0.0,Wilderness_Area_1)\n(0.0,Vertical_Distance_To_Hyrology)\n(0.0,Soil_Type_9)\n(0.0,Soil_Type_7)\n(0.0,Soil_Type_6)\n(0.0,Soil_Type_5)\n(0.0,Soil_Type_4)\n(0.0,Soil_Type_39)\n(0.0,Soil_Type_38)\n(0.0,Soil_Type_37)\n(0.0,Soil_Type_36)\n(0.0,Soil_Type_35)\n(0.0,Soil_Type_34)\n(0.0,Soil_Type_33)\n(0.0,Soil_Type_32)\n(0.0,Soil_Type_30)\n(0.0,Soil_Type_29)\n(0.0,Soil_Type_28)\n(0.0,Soil_Type_27)\n(0.0,Soil_Type_26)\n(0.0,Soil_Type_25)\n(0.0,Soil_Type_24)\n(0.0,Soil_Type_23)\n(0.0,Soil_Type_22)\n(0.0,Soil_Type_20)\n(0.0,Soil_Type_2)\n(0.0,Soil_Type_19)\n(0.0,Soil_Type_18)\n(0.0,Soil_Type_17)\n(0.0,Soil_Type_16)\n(0.0,Soil_Type_15)\n(0.0,Soil_Type_14)\n(0.0,Soil_Type_13)\n(0.0,Soil_Type_12)\n(0.0,Soil_Type_11)\n(0.0,Soil_Type_10)\n(0.0,Soil_Type_0)\n(0.0,Slope)\n(0.0,Hillshade_3pm)\n(0.0,Aspect)\n"}]},"apps":[],"jobName":"paragraph_1514015353539_-2116890507","id":"20171223-094913_838568825","dateCreated":"2017-12-23T09:49:13+0200","dateStarted":"2017-12-23T10:13:49+0200","dateFinished":"2017-12-23T10:14:15+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17178"},{"title":"Model tahminlerini bir görelim","text":"val predictions = model.transform(assembledTrainData)\npredictions.select(\"Cover_Type\",\"prediction\",\"probability\").show(truncate = false)","user":"admin","dateUpdated":"2017-12-23T16:05:57+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\npredictions: org.apache.spark.sql.DataFrame = [Elevation: int, Aspect: int ... 57 more fields]\n+----------+----------+-------------------------------------------------------------------------------------------------+\n|Cover_Type|prediction|probability                                                                                      |\n+----------+----------+-------------------------------------------------------------------------------------------------+\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |4.0       |[0.0,0.0,0.04892450442851118,0.279628848587094,0.4137494727962885,0.0,0.2576971741881063,0.0]    |\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n|6.0       |4.0       |[0.0,0.0,0.04892450442851118,0.279628848587094,0.4137494727962885,0.0,0.2576971741881063,0.0]    |\n|3.0       |3.0       |[0.0,0.0,0.038504391139074584,0.6265893301874427,0.04767990562327959,0.0,0.28722637305020315,0.0]|\n+----------+----------+-------------------------------------------------------------------------------------------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1514015351985_1210818054","id":"20171223-094911_2094795767","dateCreated":"2017-12-23T09:49:11+0200","dateStarted":"2017-12-23T16:05:57+0200","dateFinished":"2017-12-23T16:06:41+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17179"},{"text":"%md\nYukarıdaki modelde probability diye bir sütun var. Burada hedef değişkenin her bir farklı değişkenine ait olma olasılıkları veriliyor. Ancak toplam 7 olası sonuç olması beklenirken probability sütununda 8 değer var. \nİlk indistei 0.0'ı dikkate almamak gerekiyor. Kalan 1-7 arasını dikkate almak gerekiyor.\nMulticlassClassificationEvaluator doğruluğu iğer metrikleri ve modelik tahmin kalitesini hesaplayabilir ","user":"admin","dateUpdated":"2017-12-23T16:27:12+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Yukarıdaki modelde</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1514015349800_-1913758412","id":"20171223-094909_738964047","dateCreated":"2017-12-23T09:49:09+0200","dateStarted":"2017-12-23T16:07:40+0200","dateFinished":"2017-12-23T16:07:44+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17180"},{"text":"import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nval evaluator = new MulticlassClassificationEvaluator().setLabelCol(\"Cover_Type\").setPredictionCol(\"prediction\")\n\nevaluator.setMetricName(\"accuracy\").evaluate(predictions)\nevaluator.setMetricName(\"f1\").evaluate(predictions)","user":"admin","dateUpdated":"2017-12-23T16:31:32+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n\nevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_94792d235781\n\nres75: Double = 0.6984557009910032\n\nres76: Double = 0.6819043683285178\n"}]},"apps":[],"jobName":"paragraph_1513975037229_-1418225541","id":"20171222-223717_679015051","dateCreated":"2017-12-22T22:37:17+0200","dateStarted":"2017-12-23T16:31:32+0200","dateFinished":"2017-12-23T16:32:02+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17181"},{"title":"Hata Matrisi","text":"//Hata matrisi hala eski mllib RRD API'si ile olduğundan predictions dataframe'i rdd ye çevirip çalışacağız.\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\nval predictionRDD = predictions.select(\"prediction\",\"Cover_Type\").as[(Double, Double)].rdd\n\nval multiclassMetrics = new MulticlassMetrics(predictionRDD)\nmulticlassMetrics.confusionMatrix","user":"admin","dateUpdated":"2017-12-23T17:19:23+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\n\npredictionRDD: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[381] at rdd at <console>:60\n\nmulticlassMetrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@31a5c11e\n\n\n\n\n\n\n\n\nres79: org.apache.spark.mllib.linalg.Matrix =\n135338.0  50335.0   167.0    0.0    0.0   0.0  4932.0\n57268.0   192731.0  4339.0   116.0  51.0  0.0  687.0\n0.0       5289.0    26255.0  663.0  0.0   0.0  0.0\n0.0       15.0      1455.0   981.0  0.0   0.0  0.0\n0.0       7808.0    674.0    0.0    68.0  0.0  0.0\n0.0       5654.0    9433.0   611.0  0.0   0.0  0.0\n8261.0    36.0      37.0     0.0    0.0   0.0  10205.0\n"}]},"apps":[],"jobName":"paragraph_1513973610081_-1777971220","id":"20171222-221330_807142709","dateCreated":"2017-12-22T22:13:30+0200","dateStarted":"2017-12-23T17:19:23+0200","dateFinished":"2017-12-23T17:20:11+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17182"},{"title":"Aslında bu hata matrisi dataframe API si ile de yazdırılabilir","text":"val confusionMatrix = predictions.groupBy(\"Cover_Type\").pivot(\"prediction\",(1 to 7)).count().na.fill(0.0).orderBy(\"Cover_Type\")\nconfusionMatrix.show()","user":"admin","dateUpdated":"2017-12-23T17:30:24+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nconfusionMatrix: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Cover_Type: double, 1: bigint ... 6 more fields]\n+----------+------+------+-----+---+---+---+-----+\n|Cover_Type|     1|     2|    3|  4|  5|  6|    7|\n+----------+------+------+-----+---+---+---+-----+\n|       1.0|135338| 50335|  167|  0|  0|  0| 4932|\n|       2.0| 57268|192731| 4339|116| 51|  0|  687|\n|       3.0|     0|  5289|26255|663|  0|  0|    0|\n|       4.0|     0|    15| 1455|981|  0|  0|    0|\n|       5.0|     0|  7808|  674|  0| 68|  0|    0|\n|       6.0|     0|  5654| 9433|611|  0|  0|    0|\n|       7.0|  8261|    36|   37|  0|  0|  0|10205|\n+----------+------+------+-----+---+---+---+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1514039242676_1122525095","id":"20171223-162722_674941744","dateCreated":"2017-12-23T16:27:22+0200","dateStarted":"2017-12-23T17:30:24+0200","dateFinished":"2017-12-23T17:31:24+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17183"},{"title":"Baseline Accuracy nedir?","text":"// Acaba rastgele sınıflandırma yapılsa model başarısı nedir? Bizim eğittiğimiz model rastgele modelden ne kadar daha başarılı görmek için bunu bilmemiz lazım.Aşağıda accuracy %37 biz % 69 doğrulukla tahmin etmiştik.\nimport org.apache.spark.sql.DataFrame\ndef classProbabilities(data: DataFrame): Array[Double] = {\n    val total = data.count()\n    data.groupBy(\"Cover_Type\").count().orderBy(\"Cover_Type\").select(\"count\").as[Double].map(_/total).collect()\n}\n\nval trainPriorProbabilities = classProbabilities(trainData)\nval testPriorProbabilities = classProbabilities(testData)\ntrainPriorProbabilities.zip(testPriorProbabilities).map{\n    case (trainProb, cvProb) => trainProb * cvProb\n}.sum","user":"admin","dateUpdated":"2017-12-23T18:15:21+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.sql.DataFrame\n\nclassProbabilities: (data: org.apache.spark.sql.DataFrame)Array[Double]\n\ntrainPriorProbabilities: Array[Double] = Array(0.36447978540682335, 0.4875575314906698, 0.06153314138656386, 0.004682762428617009, 0.01633521777424538, 0.02999184194387181, 0.03541971956920879)\n\ntestPriorProbabilities: Array[Double] = Array(0.365744839678489, 0.48797805669843586, 0.061576653993715605, 0.005138621252365329, 0.01637067513844765, 0.028974185372289636, 0.03421696786625696)\n\nres82: Double = 0.37738540846198215\n"}]},"apps":[],"jobName":"paragraph_1514039247730_1800467981","id":"20171223-162727_354403083","dateCreated":"2017-12-23T16:27:27+0200","dateStarted":"2017-12-23T17:47:59+0200","dateFinished":"2017-12-23T17:49:09+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17184"},{"title":"Desicion Tree Hyperparameters","text":"%md\nKarar ağaçları seçmek için gerekli hiper parametreler farklı: maximum depth, maximum bins, impurity measure, minimum information gain\nmaximum depth: ağacın derinliğini sınırlar\nmaximum bins: ","user":"admin","dateUpdated":"2017-12-23T18:23:10+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"title":true,"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514039245822_-1229075506","id":"20171223-162725_1434482794","dateCreated":"2017-12-23T16:27:25+0200","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:17185"},{"title":"Tuning Decision TreeVectorAssembler ve DecisionTreeClassifier dan bir Pipeline oluşturma","text":"import org.apache.spark.ml.Pipeline\nval inputCols = trainData.columns.filter(_!=\"Cover_type\")\nval assembler = new VectorAssembler().setInputCols(inputCols).setOutputCol(\"featureVector\")\n\nval classifier = new DecisionTreeClassifier().setSeed(Random.nextLong()).setLabelCol(\"Cover_Type\").setFeaturesCol(\"featureVector\").setPredictionCol(\"prediction\")\n\nval pipeline = new Pipeline().setStages(Array(assembler, classifier))","user":"admin","dateUpdated":"2017-12-23T21:37:16+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.Pipeline\ninputCols: Array[String] = Array(Elevation, Aspect, Slope, Horizontal_Distance_To_Hyrology, Vertical_Distance_To_Hyrology, Horizontal_Distance_To_Roadways, Hillshade_9am, Hillshade_Noon, Hillshade_3pm, Horizontal_Distance_To_Fire_Points, Wilderness_Area_0, Wilderness_Area_1, Wilderness_Area_2, Wilderness_Area_3, Soil_Type_0, Soil_Type_1, Soil_Type_2, Soil_Type_3, Soil_Type_4, Soil_Type_5, Soil_Type_6, Soil_Type_7, Soil_Type_8, Soil_Type_9, Soil_Type_10, Soil_Type_11, Soil_Type_12, Soil_Type_13, Soil_Type_14, Soil_Type_15, Soil_Type_16, Soil_Type_17, Soil_Type_18, Soil_Type_19, Soil_Type_20, Soil_Type_21, Soil_Type_22, Soil_Type_23, Soil_Type_24, Soil_Type_25, Soil_Type_26, Soil_Type_27, Soil_Type_28, Soil_Type_29, Soil_Type_30, Soil_Type_31, Soil_Type_32, Soil_Type_33, Soil_Type_34, Soi...\nassembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_98f19d414d7b\n\nclassifier: org.apache.spark.ml.classification.DecisionTreeClassifier = dtc_f7650977bb4f\n\npipeline: org.apache.spark.ml.Pipeline = pipeline_0ff219e3e18a\n"}]},"apps":[],"jobName":"paragraph_1514042427772_-2058815251","id":"20171223-172027_370863759","dateCreated":"2017-12-23T17:20:27+0200","dateStarted":"2017-12-23T21:37:16+0200","dateFinished":"2017-12-23T21:37:29+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17186"},{"text":"import org.apache.spark.ml.tuning.ParamGridBuilder\nval paramGrid = new ParamGridBuilder(). addGrid(classifier.impurity, Seq(\"gini\",\"entropy\")).\n                                        addGrid(classifier.maxDepth, Seq(1,20)).\n                                        addGrid(classifier.maxBins, Seq(40,300)).\n                                        addGrid(classifier.minInfoGain, Seq(0.0,0.05)).build()","user":"admin","dateUpdated":"2017-12-23T21:44:47+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.tuning.ParamGridBuilder\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparamGrid: Array[org.apache.spark.ml.param.ParamMap] =\nArray({\n\tdtc_f7650977bb4f-impurity: gini,\n\tdtc_f7650977bb4f-maxBins: 40,\n\tdtc_f7650977bb4f-maxDepth: 1,\n\tdtc_f7650977bb4f-minInfoGain: 0.0\n}, {\n\tdtc_f7650977bb4f-impurity: gini,\n\tdtc_f7650977bb4f-maxBins: 40,\n\tdtc_f7650977bb4f-maxDepth: 20,\n\tdtc_f7650977bb4f-minInfoGain: 0.0\n}, {\n\tdtc_f7650977bb4f-impurity: gini,\n\tdtc_f7650977bb4f-maxBins: 40,\n\tdtc_f7650977bb4f-maxDepth: 1,\n\tdtc_f7650977bb4f-minInfoGain: 0.05\n}, {\n\tdtc_f7650977bb4f-impurity: gini,\n\tdtc_f7650977bb4f-maxBins: 40,\n\tdtc_f7650977bb4f-maxDepth: 20,\n\tdtc_f7650977bb4f-minInfoGain: 0.05\n}, {\n\tdtc_f7650977bb4f-impurity: gini,\n\tdtc_f7650977bb4f-maxBins: 300,\n\tdtc_f7650977bb4f-maxDepth: 1,\n\tdtc_f7650977bb4f-minInfoGain: 0.0\n}, {\n\tdtc_f7650977bb4f-impurity: gini,\n\tdtc_f7650977bb..."}]},"apps":[],"jobName":"paragraph_1514042424237_-645848724","id":"20171223-172024_1518595196","dateCreated":"2017-12-23T17:20:24+0200","dateStarted":"2017-12-23T21:44:47+0200","dateFinished":"2017-12-23T21:45:11+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17187"},{"text":"val multiClassEval = new MulticlassClassificationEvaluator().setLabelCol(\"Cover_Type\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")","user":"admin","dateUpdated":"2017-12-23T21:47:44+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nmultiClassEval: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_1f33661a8153\n"}]},"apps":[],"jobName":"paragraph_1514057864508_-1777665536","id":"20171223-213744_464730045","dateCreated":"2017-12-23T21:37:44+0200","dateStarted":"2017-12-23T21:47:44+0200","dateFinished":"2017-12-23T21:47:55+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17188"},{"text":"import org.apache.spark.ml.tuning.TrainValidationSplit\n\nval validator = new TrainValidationSplit().setSeed(Random.nextLong()).setEstimator(pipeline).setEvaluator(multiClassEval).setEstimatorParamMaps(paramGrid).setTrainRatio(0.9)\n\nval validatorModel = validator.fit(trainData)","user":"admin","dateUpdated":"2017-12-23T22:02:56+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.tuning.TrainValidationSplit\n\nvalidator: org.apache.spark.ml.tuning.TrainValidationSplit = tvs_76655209e2b0\n\nvalidatorModel: org.apache.spark.ml.tuning.TrainValidationSplitModel = tvs_76655209e2b0\n"}]},"apps":[],"jobName":"paragraph_1514057864255_-1875776505","id":"20171223-213744_1319420321","dateCreated":"2017-12-23T21:37:44+0200","dateStarted":"2017-12-23T22:02:56+0200","dateFinished":"2017-12-23T22:06:44+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17189"},{"text":"import org.apache.spark.ml.PipelineModel\nval bestModel = validatorModel.bestModel\nbestModel.asInstanceOf[PipelineModel].stages.last.extractParamMap","user":"admin","dateUpdated":"2017-12-23T22:10:26+0200","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nimport org.apache.spark.ml.PipelineModel\n\nbestModel: org.apache.spark.ml.Model[_] = pipeline_0ff219e3e18a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nres91: org.apache.spark.ml.param.ParamMap =\n{\n\tdtc_f7650977bb4f-cacheNodeIds: false,\n\tdtc_f7650977bb4f-checkpointInterval: 10,\n\tdtc_f7650977bb4f-featuresCol: featureVector,\n\tdtc_f7650977bb4f-impurity: gini,\n\tdtc_f7650977bb4f-labelCol: Cover_Type,\n\tdtc_f7650977bb4f-maxBins: 40,\n\tdtc_f7650977bb4f-maxDepth: 20,\n\tdtc_f7650977bb4f-maxMemoryInMB: 256,\n\tdtc_f7650977bb4f-minInfoGain: 0.0,\n\tdtc_f7650977bb4f-minInstancesPerNode: 1,\n\tdtc_f7650977bb4f-predictionCol: prediction,\n\tdtc_f7650977bb4f-probabilityCol: probability,\n\tdtc_f7650977bb4f-rawPredictionCol: rawPrediction,\n\tdtc_f7650977bb4f-seed: -289992390133358762\n}\n"}]},"apps":[],"jobName":"paragraph_1514057863929_-1653391641","id":"20171223-213743_1098656178","dateCreated":"2017-12-23T21:37:43+0200","dateStarted":"2017-12-23T22:10:26+0200","dateFinished":"2017-12-23T22:10:40+0200","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:17190"},{"user":"admin","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514057863853_-1636462689","id":"20171223-213743_1406766409","dateCreated":"2017-12-23T21:37:43+0200","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:17191","text":"\n//val validatorModel = validator.fit(trainData)\nval paramsAdnMetrics = validatorModel.validationMetrics.zip(validatorModel.getEstimatorParams).sortBy(-_._1)\n\nparamsAndMetrics.foreach{ case (metric, params) => \n    println(metrics)\n    println(params)\n    println()\n}","dateUpdated":"2017-12-24T20:25:18+0200","dateFinished":"2017-12-24T20:25:26+0200","dateStarted":"2017-12-24T20:25:18+0200","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"\n\n\n<console>:77: error: value getEstimatorParams is not a member of org.apache.spark.ml.tuning.TrainValidationSplitModel\n       val paramsAdnMetrics = validatorModel.validationMetrics.zip(validatorModel.getEstimatorParams).sortBy(-_._1)\n                                                                                  ^\n"}]}},{"user":"admin","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514057860729_622413427","id":"20171223-213740_457138176","dateCreated":"2017-12-23T21:37:40+0200","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:17192"},{"user":"admin","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514042420553_1816174812","id":"20171223-172020_51995826","dateCreated":"2017-12-23T17:20:20+0200","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:17193"},{"user":"admin","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514139838801_-163930044","id":"20171224-202358_1293568583","dateCreated":"2017-12-24T20:23:58+0200","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18384"},{"user":"admin","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514139833939_-1207769134","id":"20171224-202353_1459654168","dateCreated":"2017-12-24T20:23:53+0200","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18328"},{"user":"admin","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1514139823991_1238849122","id":"20171224-202343_978118264","dateCreated":"2017-12-24T20:23:43+0200","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:18259"}],"name":"SparkTraining/AdvancedAnalyticsSpark/Chapter4","id":"2D2VJ8MZF","angularObjects":{"2CHS8UYQQ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CY64P8KM:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}